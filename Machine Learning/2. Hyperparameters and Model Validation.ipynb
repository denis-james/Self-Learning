{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier the buy-n-large framework of implementing a supervised Machine Learning model.\n",
    "\n",
    "1. Choose a class of model\n",
    "2. Choose model hyperparameters\n",
    "3. Fit the model to the training data\n",
    "4. Use the model to predict labels for new data\n",
    "\n",
    "A huge part of this whole process is choosing the model, tuning the parameters of the model and then training and testing of the trained model. Let's have a deeper look into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "The concept of Model validation is pretty straight forward. Testing the prediction of the model on a provided training data with known output.\n",
    "\n",
    "Here's a naive approach to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The wrong way\n",
    "\n",
    "We've used this approach in one of the previous sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          setosa\n",
       "50     versicolor\n",
       "100     virginica\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "Dataset=sns.load_dataset('iris')\n",
    "\n",
    "X_data=Dataset.iloc[:,:4]\n",
    "Y_data=Dataset.iloc[:,4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose a model to train this data on. For this instance we'll pick k-neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model=KNeighborsClassifier(\n",
    "    n_neighbors=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_data,Y_data)\n",
    "Y_pred=model.predict(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we calculate it's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "# confusion_matrix(Y_data,Y_pred)\n",
    "accuracy_score(Y_data,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the accuracy above, it should be pretty evident that our model is performing perfectly which is false. Our model trains and evaluates on the same data. Furthermore, the K-nearest-neighbourhood algorithm is an instance based algorithm. i.e. it simply stores the data and predicts the labels of each new data point based on the class of the nearest data points in the training dataset. Here the each data point it tries to predict the label of is already in the dataset. It'll obviously be always right in such a case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The right way: Holdout Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correct evaluation can be made by training the model on a subset of the dataset so that we don't over train the model and our evaluation method stays more critical and realistic during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_test,X_train,Y_test,Y_train=train_test_split(X_data,Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928571428571429"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, although our model is not performing perfectly, the accuracy seems more realistic and true since it was tested on data that the model was oblivious of while training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
